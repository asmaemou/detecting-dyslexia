{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /Users/asmae/Library/Python/3.9/lib/python/site-packages (3.9.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/asmae/Library/Python/3.9/lib/python/site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Users/asmae/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.2.1)\n",
      "Requirement already satisfied: pillow>=8 in /Users/asmae/Library/Python/3.9/lib/python/site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/asmae/Library/Python/3.9/lib/python/site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/asmae/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/asmae/Library/Python/3.9/lib/python/site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/asmae/Library/Python/3.9/lib/python/site-packages (from matplotlib) (4.53.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/asmae/Library/Python/3.9/lib/python/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /Users/asmae/Library/Python/3.9/lib/python/site-packages (from matplotlib) (6.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/asmae/Library/Python/3.9/lib/python/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /Users/asmae/Library/Python/3.9/lib/python/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.19.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.15.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: scipy in /Users/asmae/Library/Python/3.9/lib/python/site-packages (1.13.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.22.4 in /Users/asmae/Library/Python/3.9/lib/python/site-packages (from scipy) (1.26.4)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.0-cp39-cp39-macosx_12_0_arm64.whl (11.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.0 MB 7.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/asmae/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /Users/asmae/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.26.4)\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[K     |████████████████████████████████| 301 kB 10.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.0 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 24.0 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Name: scikit-learn\n",
      "Version: 1.5.0\n",
      "Summary: A set of python modules for machine learning and data mining\n",
      "Home-page: https://scikit-learn.org\n",
      "Author: \n",
      "Author-email: \n",
      "License: new BSD\n",
      "Location: /Users/asmae/Library/Python/3.9/lib/python/site-packages\n",
      "Requires: scipy, numpy, joblib, threadpoolctl\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip3 install matplotlib\n",
    "!pip3 install scipy\n",
    "!pip3 install scikit-learn\n",
    "!pip3 show scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a simple CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 151649 images belonging to 3 classes.\n",
      "Found 56723 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "base_dir = '/Users/asmae/Documents/GitHub/detecting-dyslexia/Gambo'  \n",
    "\n",
    "train_dir = os.path.join(base_dir, 'Train')\n",
    "test_dir = os.path.join(base_dir, 'Test')\n",
    "\n",
    "# Data Augmentation and Normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asmae/Library/Python/3.9/lib/python/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Build the Model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # Adjust the output layer according to the number of classes\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # Adjust the output layer according to the number of classes\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asmae/Library/Python/3.9/lib/python/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1476s\u001b[0m 311ms/step - accuracy: 0.6276 - loss: 0.7888 - val_accuracy: 0.6503 - val_loss: 0.7116\n",
      "Epoch 2/25\n",
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16us/step - accuracy: 0.8750 - loss: 0.3815 - val_accuracy: 0.6842 - val_loss: 0.8885\n",
      "Epoch 3/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 12:53:10.541750: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py:135: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(type, value, traceback)\n",
      "2024-06-18 12:53:10.601330: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1454s\u001b[0m 307ms/step - accuracy: 0.7492 - loss: 0.5306 - val_accuracy: 0.6715 - val_loss: 0.6849\n",
      "Epoch 4/25\n",
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13us/step - accuracy: 0.7812 - loss: 0.4982 - val_accuracy: 0.5263 - val_loss: 0.6703\n",
      "Epoch 5/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 13:17:24.620644: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-06-18 13:17:24.671017: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1387s\u001b[0m 293ms/step - accuracy: 0.7664 - loss: 0.4881 - val_accuracy: 0.6779 - val_loss: 0.7031\n",
      "Epoch 6/25\n",
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13us/step - accuracy: 0.8750 - loss: 0.3851 - val_accuracy: 0.5263 - val_loss: 0.9445\n",
      "Epoch 7/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 13:40:32.010052: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-06-18 13:40:32.061810: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1358s\u001b[0m 287ms/step - accuracy: 0.7788 - loss: 0.4594 - val_accuracy: 0.6841 - val_loss: 0.7065\n",
      "Epoch 8/25\n",
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13us/step - accuracy: 0.9062 - loss: 0.3379 - val_accuracy: 0.7368 - val_loss: 0.5180\n",
      "Epoch 9/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 14:03:10.548256: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-06-18 14:03:10.599497: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1402s\u001b[0m 296ms/step - accuracy: 0.7862 - loss: 0.4434 - val_accuracy: 0.6906 - val_loss: 0.6795\n",
      "Epoch 10/25\n",
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13us/step - accuracy: 0.7812 - loss: 0.4247 - val_accuracy: 0.6842 - val_loss: 0.6665\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 14:26:33.358216: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-06-18 14:26:33.411386: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1693s\u001b[0m 357ms/step - accuracy: 0.7923 - loss: 0.4292 - val_accuracy: 0.6956 - val_loss: 0.7425\n",
      "Epoch 12/25\n",
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11us/step - accuracy: 0.7812 - loss: 0.4891 - val_accuracy: 0.4211 - val_loss: 1.2706\n",
      "Epoch 13/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 14:54:46.370371: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-06-18 14:54:46.414854: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4342s\u001b[0m 916ms/step - accuracy: 0.7968 - loss: 0.4171 - val_accuracy: 0.6959 - val_loss: 0.6944\n",
      "Epoch 14/25\n",
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12us/step - accuracy: 0.8438 - loss: 0.3941 - val_accuracy: 0.7368 - val_loss: 0.3804\n",
      "Epoch 15/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 16:07:08.836290: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-06-18 16:07:08.883232: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1376s\u001b[0m 290ms/step - accuracy: 0.8028 - loss: 0.4016 - val_accuracy: 0.6954 - val_loss: 0.8302\n",
      "Epoch 16/25\n",
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23us/step - accuracy: 0.8750 - loss: 0.3186 - val_accuracy: 0.7895 - val_loss: 0.6732\n",
      "Epoch 17/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 16:30:05.398981: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-06-18 16:30:05.494890: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1378s\u001b[0m 291ms/step - accuracy: 0.8066 - loss: 0.3920 - val_accuracy: 0.6884 - val_loss: 0.7686\n",
      "Epoch 18/25\n",
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12us/step - accuracy: 0.9062 - loss: 0.2604 - val_accuracy: 0.6842 - val_loss: 0.5809\n",
      "Epoch 19/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 16:53:04.091889: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-06-18 16:53:04.139342: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1415s\u001b[0m 299ms/step - accuracy: 0.8107 - loss: 0.3860 - val_accuracy: 0.6924 - val_loss: 0.8324\n",
      "Epoch 20/25\n",
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12us/step - accuracy: 0.6875 - loss: 0.5088 - val_accuracy: 0.5789 - val_loss: 0.9668\n",
      "Epoch 21/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 17:16:39.466256: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-06-18 17:16:39.512893: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2248s\u001b[0m 474ms/step - accuracy: 0.8130 - loss: 0.3795 - val_accuracy: 0.6640 - val_loss: 0.9722\n",
      "Epoch 22/25\n",
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9us/step - accuracy: 0.8438 - loss: 0.3038 - val_accuracy: 0.8421 - val_loss: 0.3673\n",
      "Epoch 23/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 17:54:08.119387: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-06-18 17:54:08.156110: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1485s\u001b[0m 313ms/step - accuracy: 0.8144 - loss: 0.3769 - val_accuracy: 0.7065 - val_loss: 0.7985\n",
      "Epoch 24/25\n",
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11us/step - accuracy: 0.8438 - loss: 0.3231 - val_accuracy: 0.8947 - val_loss: 0.4072\n",
      "Epoch 25/25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-18 18:18:53.170030: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-06-18 18:18:53.215440: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4851s\u001b[0m 1s/step - accuracy: 0.8162 - loss: 0.3707 - val_accuracy: 0.6718 - val_loss: 0.9366\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=25,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // test_generator.batch_size\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is the simple CNN after i have add to it : F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 151649 images belonging to 3 classes.\n",
      "Found 56723 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "base_dir = '/Users/asmae/Documents/GitHub/detecting-dyslexia/Gambo'  \n",
    "\n",
    "train_dir = os.path.join(base_dir, 'Train')\n",
    "test_dir = os.path.join(base_dir, 'Test')\n",
    "\n",
    "# Data Augmentation and Normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create Generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the Model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='softmax')  # Adjust the output layer according to the number of classes\n",
    "])\n",
    "\n",
    "# Compile the Model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Early Stopping Callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asmae/Library/Python/3.9/lib/python/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2415s\u001b[0m 509ms/step - accuracy: 0.6416 - loss: 0.7687 - val_accuracy: 0.6735 - val_loss: 0.6561\n",
      "Epoch 2/8\n",
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10us/step - accuracy: 0.6875 - loss: 0.7559 - val_accuracy: 0.0526 - val_loss: 1.2238\n",
      "Epoch 3/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 13:24:18.270167: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/contextlib.py:135: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self.gen.throw(type, value, traceback)\n",
      "2024-06-21 13:24:18.307262: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3549s\u001b[0m 749ms/step - accuracy: 0.7536 - loss: 0.5199 - val_accuracy: 0.6928 - val_loss: 0.6499\n",
      "Epoch 4/8\n",
      "\u001b[1m4739/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9us/step - accuracy: 0.6875 - loss: 0.5108 - val_accuracy: 0.1579 - val_loss: 1.4990\n",
      "Epoch 5/8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 14:23:27.306447: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n",
      "2024-06-21 14:23:27.342188: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4671/4739\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m15s\u001b[0m 230ms/step - accuracy: 0.7752 - loss: 0.4714"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=8,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.samples // test_generator.batch_size,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Save the Model\n",
    "model.save('my_model.h5')  # Save the model to a file named 'my_model.h5'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the Model\n",
    "test_steps = test_generator.samples // test_generator.batch_size\n",
    "predictions = model.predict(test_generator, steps=test_steps+1)\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes\n",
    "class_labels = list(test_generator.class_indices.keys())\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(true_classes, predicted_classes)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Classification Report - includes Precision, Recall, and F1 Score\n",
    "report = classification_report(true_classes, predicted_classes, target_names=class_labels)\n",
    "print(\"Classification Report:\")\n",
    "print(report)\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(class_labels))\n",
    "plt.xticks(tick_marks, class_labels, rotation=45)\n",
    "plt.yticks(tick_marks, class_labels)\n",
    "\n",
    "fmt = 'd'\n",
    "thresh = conf_matrix.max() / 2.\n",
    "for i, j in np.ndindex(conf_matrix.shape):\n",
    "    plt.text(j, i, format(conf_matrix[i, j], fmt),\n",
    "             ha=\"center\", va=\"center\",\n",
    "             color=\"white\" if conf_matrix[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  **OmniVec-like**\n",
    "  More advanced model architecture that resembles the functionality and complexity of OmniVec. Since OmniVec is not a standard model, we'll implement a complex Convolutional Neural Network (CNN) with multiple layers, similar to how OmniVec would be structured.\n",
    "\n",
    "\n",
    "I'll provide a detailed model architecture using TensorFlow/Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 121321 images belonging to 3 classes.\n",
      "Found 30328 images belonging to 3 classes.\n",
      "Found 56723 images belonging to 3 classes.\n",
      "Epoch 1/3\n",
      "\u001b[1m3791/3791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56795s\u001b[0m 15s/step - accuracy: 0.2718 - loss: 5828378624000.0000 - val_accuracy: 0.2593 - val_loss: 0.4141\n",
      "Epoch 2/3\n",
      "\u001b[1m   1/3791\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4:36:52\u001b[0m 4s/step - accuracy: 0.4062 - loss: 0.1411"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 12:10:39.549166: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3791/3791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 273us/step - accuracy: 0.4062 - loss: 0.1411 - val_accuracy: 0.2917 - val_loss: 0.5138\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 12:10:40.560029: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "\t [[{{node IteratorGetNext}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3791/3791\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62972s\u001b[0m 17s/step - accuracy: 0.2606 - loss: 0.3894 - val_accuracy: 0.2594 - val_loss: 0.3740\n",
      "\u001b[1m1773/1773\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21209s\u001b[0m 12s/step - accuracy: 0.3447 - loss: 0.1962\n",
      "Test accuracy: 0.3447807729244232\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D, concatenate\n",
    "\n",
    "# Set the correct paths for train_dir and test_dir\n",
    "train_dir = '/Users/asmae/Documents/GitHub/detecting-dyslexia/Gambo/Train'\n",
    "test_dir = '/Users/asmae/Documents/GitHub/detecting-dyslexia/Gambo/Test'\n",
    "\n",
    "# Prepare data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='training')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary',\n",
    "    subset='validation')\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary')\n",
    "\n",
    "# Define the OmniVec model\n",
    "input_layer = Input(shape=(150, 150, 3))\n",
    "\n",
    "# First block\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
    "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Second block\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Third block\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Fourth block\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "# Global Average Pooling\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "# Fully connected layers\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Output layer\n",
    "output_layer = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Create the model\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // 32,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // 32,\n",
    "    epochs=3\n",
    ")\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f'Test accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Count the total number of images in train and test directories.\n",
    "Count the number of images in each class within train and test.\n",
    "Perform data augmentation if there are imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import Counter\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define paths\n",
    "base_dir = '/Users/asmae/Documents/GitHub/detecting-dyslexia/Gambo'  \n",
    "train_dir = os.path.join(base_dir, 'Train')\n",
    "test_dir = os.path.join(base_dir, 'Test')\n",
    "\n",
    "# Function to count images in each directory\n",
    "def count_images(directory):\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        count += len(files)\n",
    "    return count\n",
    "\n",
    "# Function to count images in each class\n",
    "def count_images_per_class(directory):\n",
    "    class_counts = {}\n",
    "    for class_dir in os.listdir(directory):\n",
    "        class_path = os.path.join(directory, class_dir)\n",
    "        if os.path.isdir(class_path):\n",
    "            class_counts[class_dir] = count_images(class_path)\n",
    "    return class_counts\n",
    "\n",
    "# Count total images\n",
    "total_train_images = count_images(train_dir)\n",
    "total_test_images = count_images(test_dir)\n",
    "\n",
    "print(f\"Total images in train: {total_train_images}\")\n",
    "print(f\"Total images in test: {total_test_images}\")\n",
    "\n",
    "# Count images per class in train and test\n",
    "train_class_counts = count_images_per_class(train_dir)\n",
    "test_class_counts = count_images_per_class(test_dir)\n",
    "\n",
    "print(\"Images per class in train:\")\n",
    "for class_name, count in train_class_counts.items():\n",
    "    print(f\"  {class_name}: {count}\")\n",
    "\n",
    "print(\"Images per class in test:\")\n",
    "for class_name, count in test_class_counts.items():\n",
    "    print(f\"  {class_name}: {count}\")\n",
    "\n",
    "# Perform data augmentation if classes are imbalanced\n",
    "min_class_count = min(train_class_counts.values())\n",
    "\n",
    "# Data augmentation and normalization\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Function to augment data for a class if it is imbalanced\n",
    "def augment_class(directory, class_name, target_count):\n",
    "    class_path = os.path.join(directory, class_name)\n",
    "    current_count = len(os.listdir(class_path))\n",
    "    if current_count < target_count:\n",
    "        datagen = ImageDataGenerator(\n",
    "            rescale=1./255,\n",
    "            rotation_range=20,\n",
    "            width_shift_range=0.2,\n",
    "            height_shift_range=0.2,\n",
    "            shear_range=0.2,\n",
    "            zoom_range=0.2,\n",
    "            horizontal_flip=True,\n",
    "            fill_mode='nearest'\n",
    "        )\n",
    "        batch_size = 32\n",
    "        target_batches = (target_count - current_count) // batch_size + 1\n",
    "        generator = datagen.flow_from_directory(\n",
    "            directory,\n",
    "            classes=[class_name],\n",
    "            target_size=(150, 150),\n",
    "            batch_size=batch_size,\n",
    "            class_mode='categorical',\n",
    "            save_to_dir=class_path,\n",
    "            save_prefix='aug',\n",
    "            save_format='jpeg'\n",
    "        )\n",
    "        for i in range(target_batches):\n",
    "            generator.next()\n",
    "            print(f\"Augmented batch {i+1} for class {class_name}\")\n",
    "\n",
    "# Augment data for classes in train if needed\n",
    "for class_name, count in train_class_counts.items():\n",
    "    augment_class(train_dir, class_name, min_class_count)\n",
    "\n",
    "print(\"Data augmentation completed if needed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Related work: A.dataset: Table 1 Script to Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "# Define paths\n",
    "base_dir = '/Users/asmae/Documents/GitHub/detecting-dyslexia/Gambo'  \n",
    "train_dir = os.path.join(base_dir, 'Train')\n",
    "test_dir = os.path.join(base_dir, 'Test')\n",
    "\n",
    "# Function to count images in each directory\n",
    "def count_images(directory):\n",
    "    count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        count += len(files)\n",
    "    return count\n",
    "\n",
    "# Function to count images in each class\n",
    "def count_images_per_class(directory):\n",
    "    class_counts = {}\n",
    "    for class_dir in os.listdir(directory):\n",
    "        class_path = os.path.join(directory, class_dir)\n",
    "        if os.path.isdir(class_path):\n",
    "            class_counts[class_dir] = count_images(class_path)\n",
    "    return class_counts\n",
    "\n",
    "# Function to get the resolution of images\n",
    "def get_image_resolution(directory):\n",
    "    resolutions = set()\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(('png', 'jpg', 'jpeg')):\n",
    "                img_path = os.path.join(root, file)\n",
    "                with Image.open(img_path) as img:\n",
    "                    resolutions.add(img.size)\n",
    "    return resolutions\n",
    "\n",
    "# Count total images\n",
    "total_train_images = count_images(train_dir)\n",
    "total_test_images = count_images(test_dir)\n",
    "\n",
    "# Count images per class in train and test\n",
    "train_class_counts = count_images_per_class(train_dir)\n",
    "test_class_counts = count_images_per_class(test_dir)\n",
    "\n",
    "# Get image resolutions\n",
    "train_resolutions = get_image_resolution(train_dir)\n",
    "test_resolutions = get_image_resolution(test_dir)\n",
    "\n",
    "# Prepare data for the table\n",
    "data = {\n",
    "    'Feature': [\n",
    "        'Purpose', \n",
    "        'Image source', \n",
    "        'Resolution', \n",
    "        'Number of images', \n",
    "        'Number of positive examples', \n",
    "        'Number of classes', \n",
    "        'Number of segmented images', \n",
    "        'Labeling Format'\n",
    "    ],\n",
    "    'Details': [\n",
    "        'Dyslexia handwriting recognition',  # Purpose\n",
    "        'NIST Special Database 19, Kaggle, Seberang Jaya primary school',  # Image source\n",
    "        f'Train: {train_resolutions}, Test: {test_resolutions}',  # Resolution\n",
    "        f'Train: {total_train_images}, Test: {total_test_images}',  # Number of images\n",
    "        f'Train: {sum(train_class_counts.values())}, Test: {sum(test_class_counts.values())}',  # Number of positive examples\n",
    "        f'Train: {len(train_class_counts)}, Test: {len(test_class_counts)}',  # Number of classes\n",
    "        'N/A',  # Number of segmented images (if applicable, otherwise N/A)\n",
    "        'CSV with labels (0: Normal, 1: Reversal, 2: Corrected)'  # Labeling Format\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display the table\n",
    "print(df)\n",
    "\n",
    "# Save the table to a CSV file\n",
    "df.to_csv('dataset_features_summary.csv', index=False)\n",
    "\n",
    "print(\"Summary table saved to 'dataset_features_summary.csv'.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
